{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sk8s\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_image = False\n",
    "populate_reference = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the docker image for our NGS jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcr.io/jared-genome-analysis/ngs-1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if build_image:\n",
    "    image = sk8s.docker_build(image_name=\"ngs-1\",\n",
    "                              conda=[\"bwa\", \"gatk4\", \"samtools\", \"google-cloud-sdk\", \"bedtools\"],\n",
    "                              channels=[\"conda-forge\", \"bioconda\"],\n",
    "                              pip=[\"numpy\", \"scipy\", \"matplotlib\", \"pandas\", \"pysam\"],\n",
    "                              additional_config=\"RUN apt-get install -y gcc python3-dev python3-setuptools && pip3 uninstall crcmod && pip3 install --no-cache-dir -U crcmod\")\n",
    "else:    \n",
    "    image = \"gcr.io/jared-genome-analysis/ngs-1\"\n",
    "    #image = \"ngs-1\"\n",
    "\n",
    "image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a volume to hold the reference genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reference-volume'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a volume to store the reference\n",
    "if populate_reference:\n",
    "    reference_volume = sk8s.create_volume(\"100Gi\", name=\"reference-volume\")\n",
    "else:\n",
    "    reference_volume = \"reference-volume\"\n",
    "\n",
    "# Note the default volumes that jobs should mount\n",
    "default_volumes={reference_volume: f\"/mnt/{reference_volume}\"}\n",
    "#default_volumes[\"gcs-creds\"] = f\"/root/.config/gcloud\"\n",
    "\n",
    "def populate_reference_volume(volume):\n",
    "    import subprocess\n",
    "\n",
    "    def run_silent(cmd):\n",
    "        return subprocess.run(cmd, check=True, shell=True,\n",
    "                              stdout=subprocess.PIPE,\n",
    "                              stderr=subprocess.PIPE)\n",
    "\n",
    "    result = run_silent(f\"\"\"mkdir -p /mnt/{volume}/GRCh38/\"\"\")\n",
    "    result = run_silent(f\"\"\"gsutil -m rsync -r  gs://jared-genome/ref/GRCh38/ /mnt/{volume}/GRCh38/\"\"\")\n",
    "    return \"OK\"\n",
    "\n",
    "if populate_reference:\n",
    "    sk8s.run(populate_reference_volume, reference_volume,\n",
    "             name=\"populate-ref-{s}\", volumes=default_volumes, image=image, asynchro=False)\n",
    "\n",
    "reference_volume"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a very helpful utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(cmd):\n",
    "    import subprocess\n",
    "\n",
    "    result = subprocess.run(cmd,\n",
    "                            check=False,\n",
    "                            shell=True,\n",
    "                            stdout=subprocess.PIPE,\n",
    "                            stderr=subprocess.STDOUT,\n",
    "                            encoding=\"utf-8\")\n",
    "    if result.returncode == 0:\n",
    "        return result.stdout\n",
    "    else:\n",
    "        print(\"Error Running Command.\")\n",
    "        print(\"Command:\", cmd)\n",
    "        print(\"Log:\")\n",
    "        print(result.stdout)\n",
    "        raise subprocess.CalledProcessError(result.returncode, cmd=cmd, output=result.stdout)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare input data (not really part of the pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Jobs job-gmjuv failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 45\u001b[0m\n\u001b[0;32m     38\u001b[0m     fastqs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(sk8s\u001b[39m.\u001b[39mwait, jobs))\n\u001b[0;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m sk8s\u001b[39m.\u001b[39mrun(concatenate, fastqs, output_file,\n\u001b[0;32m     41\u001b[0m                     image\u001b[39m=\u001b[39mimage, volumes\u001b[39m=\u001b[39mdefault_volumes,\n\u001b[0;32m     42\u001b[0m                     asynchro\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 45\u001b[0m results \u001b[39m=\u001b[39m sk8s\u001b[39m.\u001b[39;49mrun(generate_fq, \u001b[39m\"\u001b[39;49m\u001b[39mgs://jared-genome/jared.bam\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mint\u001b[39;49m(\u001b[39m1e6\u001b[39;49m), \u001b[39m\"\u001b[39;49m\u001b[39mgs://jared-genome/jared_interleaved.fq\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     46\u001b[0m                    image\u001b[39m=\u001b[39;49mimage,\n\u001b[0;32m     47\u001b[0m                    volumes\u001b[39m=\u001b[39;49mdefault_volumes,\n\u001b[0;32m     48\u001b[0m                    asynchro\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     49\u001b[0m results\n",
      "File \u001b[1;32mc:\\Users\\jared\\Desktop\\jobs\\sk8s\\jobs.py:165\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(func, image, volumes, requests, limits, asynchro, timeout, job_template, imagePullPolicy, backoffLimit, name, test, dryrun, state, config, export_config, debug, *args)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[39mreturn\u001b[39;00m job\n\u001b[0;32m    164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 165\u001b[0m     \u001b[39mreturn\u001b[39;00m wait(job, timeout\u001b[39m=\u001b[39;49mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\jared\\Desktop\\jobs\\sk8s\\jobs.py:270\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(jobs, timeout, verbose, delete, polling_interval)\u001b[0m\n\u001b[0;32m    267\u001b[0m results \u001b[39m=\u001b[39m {d[\u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m]: check_job_status_json(d) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data[\u001b[39m\"\u001b[39m\u001b[39mitems\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[0;32m    269\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(failures) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 270\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mJobs \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(failures)\u001b[39m}\u001b[39;00m\u001b[39m failed.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    272\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(jobs) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    273\u001b[0m     \u001b[39mreturn\u001b[39;00m [actual_results[job] \u001b[39mfor\u001b[39;00m job \u001b[39min\u001b[39;00m jobs]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Jobs job-gmjuv failed."
     ]
    }
   ],
   "source": [
    "def generate_fq_chunk(bam, region, output_fq):\n",
    "    import os\n",
    "\n",
    "    token = run(\"gcloud auth application-default print-access-token\").strip()\n",
    "    os.environ[\"GCS_OAUTH_TOKEN\"] = token\n",
    "\n",
    "    run(f\"samtools view -b {bam} {region} > ./in.bam\")\n",
    "    run(f\"samtools index in.bam\")\n",
    "    run(f\"samtools collate in.bam out\")\n",
    "    run(f\"samtools fastq -o out.fq out.bam\")\n",
    "    run(f\"gsutil cp out.fq {output_fq}\")\n",
    "\n",
    "    return output_fq\n",
    "\n",
    "\n",
    "def concatenate(input_files, output_file):\n",
    "    import os\n",
    "    run(\"mkdir ./data/\")\n",
    "    run(f\"gsutil -m cp {' '.join(input_files)} ./data/\")\n",
    "    local_input_files = [\"./data/\" + os.path.basename(f) for f in input_files]\n",
    "    run(f\"cat {' '.join(local_input_files)} > out\")\n",
    "    run(f\"gsutil cp out {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "\n",
    "def generate_fq(bam, region_size, output_file):\n",
    "    import subprocess\n",
    "    cmd = f'bedtools makewindows -g /mnt/{{reference_volume}}/GRCh38/Homo_sapiens_assembly38.fasta.genome -w {region_size} | grep -vP \"_|HLA\"'\n",
    "\n",
    "    regions = [\"{}:{}-{}\".format(*(r.split(\"\\t\")))\n",
    "               for r in\n",
    "               sk8s.run(cmd, image=image, volumes=default_volumes).strip().split(\"\\n\")]\n",
    "\n",
    "    jobs = [sk8s.run(generate_fq_chunk, bam, region, f\"gs://jared-genome/sk8s/pipeline_test_1/fastq/chunk_{idx}.fq\",\n",
    "                     image=image, volumes=default_volumes, asynchro=True)\n",
    "            for idx, region in enumerate(regions)]\n",
    "\n",
    "    fastqs = list(map(sk8s.wait, jobs))\n",
    "\n",
    "    return sk8s.run(concatenate, fastqs, output_file,\n",
    "                    image=image, volumes=default_volumes,\n",
    "                    asynchro=False)\n",
    "\n",
    "\n",
    "results = sk8s.run(generate_fq, \"gs://jared-genome/jared.bam\", int(1e6), \"gs://jared-genome/jared_interleaved.fq\",\n",
    "                   image=image,\n",
    "                   volumes=default_volumes,\n",
    "                   asynchro=False)\n",
    "results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define pipeline tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_fastq(fastq, n_chunks, output_prefix):\n",
    "    import os\n",
    "\n",
    "    run(f\"gsutil cp {fastq} ./input.fq\")\n",
    "\n",
    "    os.mkdir(\"./output/\")\n",
    "    output_files = [f\"./output/chunk_{i}.fq\" for i in range(n_chunks)]\n",
    "    output_fds = [open(f, \"w\") for f in output_files]\n",
    "    current_output = 0\n",
    "    \n",
    "    with open(\"input.fq\") as fp:\n",
    "        while True:\n",
    "            name = fp.readline()\n",
    "            seq = fp.readline()\n",
    "            strand = fp.readline()\n",
    "            qual = fp.readline()\n",
    "            if name == \"\": break\n",
    "            print(name, seq, strand, qual, sep=\"\\n\", end=\"\", file=output_fds[current_output])\n",
    "            current_output = (current_output + 1) % n_chunks\n",
    "    \n",
    "    [f.close() for f in output_fds]\n",
    "\n",
    "    fastqs = []\n",
    "    for idx, file in enumerate(output_files):\n",
    "        fastqs.append(f\"{output_prefix}{idx}.fq\")\n",
    "        run(f\"gsutil cp {file} {output_prefix}{idx}.fq\")\n",
    "\n",
    "    return fastqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align(fq, output_bam, reference, read_group):\n",
    "    run(f\"gsutil -m cp {fq} ./fq.fq\")\n",
    "    run(f'bwa mem -p -R \"{read_group}\" {reference} fq.fq | samtools sort > out.bam')\n",
    "    run(f\"samtools index out.bam\")\n",
    "    run(f\"gsutil -m cp out.bam {output_bam}\")\n",
    "    run(f\"gsutil -m cp out.bam.bai {output_bam}.bai\")\n",
    "    return output_bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_bams(bams, output_bam):\n",
    "    import os\n",
    "    import dill as pickle\n",
    "\n",
    "    os.mkdir(\"./bams/\")\n",
    "\n",
    "    bams_str = \" \".join(bams)\n",
    "    bais_str = \" \".join([f\"{b}.bai\" for b in bams])\n",
    "    run(f\"gsutil -m cp {bais_str} ./bams/\")\n",
    "    run(f\"gsutil -m cp {bams_str} ./bams/\")\n",
    "\n",
    "    run(f\"samtools merge ./out.bam ./bams/*.bam\")\n",
    "    run(f\"samtools index out.bam\")\n",
    "    run(f\"gsutil cp out.bam {output_bam}\")\n",
    "    run(f\"gsutil cp out.bam.bai {output_bam}.bai\")\n",
    "    return output_bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_snps(reference, bam, roi, output_vcf):\n",
    "    import subprocess\n",
    "\n",
    "    #def run_and_log(cmd):\n",
    "    #    proc = subprocess.run(cmd, check=True, shell=True, encoding=\"utf-8\",\n",
    "    #                          stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    #    return dict(cmd=cmd,\n",
    "    #                returncode=proc.returncode,\n",
    "    #                stdout=proc.stdout,\n",
    "    #                stderr=proc.stderr)\n",
    "\n",
    "    region = \"%s:%d-%d\" % roi\n",
    "\n",
    "    run(f\"gsutil cp {bam} ./in.bam\")\n",
    "    run(f\"gsutil cp {bam}.bai ./in.bam.bai\")\n",
    "    run(f\"gatk HaplotypeCaller -R {reference} -I in.bam -O out.vcf -L {region}\")\n",
    "    run(f\"gsutil cp out.vcf {output_vcf}\")\n",
    "\n",
    "    return output_vcf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference=f\"/mnt/{reference_volume}/GRCh38/Homo_sapiens_assembly38.fasta\"\n",
    "sample_name=\"jared\"\n",
    "read_group=f'@RG\\\\tID:{sample_name}\\\\tSM:{sample_name}\\\\tPL:ILLUMINA'\n",
    "#ROI = (\"chr1\", 14674463, 14697776)\n",
    "#chr1:925,893-935,453\n",
    "ROI = (\"chr1\", 925893, 935453)\n",
    "#fq = \"gs://jared-genome/jared_interleaved.fq\"\n",
    "fq = \"gs://jared-genome/tiny_interleaved.fq\"\n",
    "output_prefix = \"gs://jared-genome/sk8s/pipeline_test_1/\"\n",
    "output_bam = f\"{output_prefix}bams/{sample_name}.bam\"\n",
    "output_vcf = f\"{output_prefix}snps/{sample_name}.vcf\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide the unaligned reads into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://jared-genome/sk8s/pipeline_test_1/fastq_chunks/chunk_0.fq',\n",
       " 'gs://jared-genome/sk8s/pipeline_test_1/fastq_chunks/chunk_1.fq',\n",
       " 'gs://jared-genome/sk8s/pipeline_test_1/fastq_chunks/chunk_2.fq']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastqs = sk8s.run(split_fastq, fq, 3, f\"{output_prefix}fastq_chunks/chunk_\",\n",
    "                  image=image, volumes=default_volumes, asynchro=False)\n",
    "fastqs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align each chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://jared-genome/sk8s/pipeline_test_1/bam_chunks/chunk_0.bam',\n",
       " 'gs://jared-genome/sk8s/pipeline_test_1/bam_chunks/chunk_1.bam',\n",
       " 'gs://jared-genome/sk8s/pipeline_test_1/bam_chunks/chunk_2.bam']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bams = sk8s.map(lambda fq: align(fq, output_prefix + \"bam_chunks/\" + re.sub(\"\\.fq$\", \".bam\", os.path.basename(fq)), reference, read_group), fastqs,\n",
    "                image=image, volumes=default_volumes,\n",
    "                requests={\"memory\": \"8Gi\", \"ephemeral-storage\": \"10Gi\", \"cpu\": \"1\"},\n",
    "                limits={\"memory\": \"8Gi\", \"ephemeral-storage\": \"10Gi\"},\n",
    "                asynchro=False)\n",
    "\n",
    "bams"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the aligned chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://jared-genome/sk8s/pipeline_test_1/bams/jared.bam'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bam = sk8s.run(merge_bams, bams, output_bam,\n",
    "               image=image, volumes=default_volumes,\n",
    "               requests={\"memory\": \"8Gi\", \"ephemeral-storage\": \"10Gi\", \"cpu\": \"1\"},\n",
    "               limits={\"memory\": \"8Gi\", \"ephemeral-storage\": \"10Gi\"},\n",
    "               asynchro=False)\n",
    "bam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Call SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://jared-genome/sk8s/pipeline_test_1/snps/jared.vcf'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snp_result = sk8s.run(call_snps, reference, bam, ROI, output_vcf,\n",
    "                       image=image, asynchro=False, volumes=default_volumes,\n",
    "                       requests={\"memory\": \"8Gi\", \"ephemeral-storage\": \"10Gi\", \"cpu\": \"2\"},\n",
    "                       limits={\"memory\": \"8Gi\", \"ephemeral-storage\": \"10Gi\"})\n",
    "snp_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have a look 🧬👀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t926250\t.\tG\tA\t689.77\t.\tAC=2;AF=1.00;AN=2;DP=20;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=25.36;SOR=0.693\tGT:AD:DP:GQ:PL\t1/1:0,18:18:54:718,54,0\n",
      "chr1\t926428\t.\tA\tG\t798.77\t.\tAC=2;AF=1.00;AN=2;DP=21;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=28.73;SOR=1.127\tGT:AD:DP:GQ:PL\t1/1:0,20:20:60:827,60,0\n",
      "chr1\t926713\t.\tT\tC\t909.77\t.\tAC=2;AF=1.00;AN=2;DP=25;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=30.97;SOR=0.776\tGT:AD:DP:GQ:PL\t1/1:0,23:23:69:938,69,0\n",
      "chr1\t926744\t.\tA\tG\t1056.77\t.\tAC=2;AF=1.00;AN=2;DP=27;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=27.24;SOR=1.220\tGT:AD:DP:GQ:PL\t1/1:0,26:26:78:1085,78,0\n",
      "chr1\t927003\t.\tC\tT\t779.77\t.\tAC=2;AF=1.00;AN=2;DP=18;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=28.20;SOR=0.914\tGT:AD:DP:GQ:PL\t1/1:0,18:18:54:808,54,0\n",
      "chr1\t927009\t.\tA\tG\t860.77\t.\tAC=2;AF=1.00;AN=2;DP=20;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=25.00;SOR=0.892\tGT:AD:DP:GQ:PL\t1/1:0,20:20:60:889,60,0\n",
      "chr1\t927486\t.\tC\tT\t1021.77\t.\tAC=2;AF=1.00;AN=2;DP=26;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=29.56;SOR=0.846\tGT:AD:DP:GQ:PL\t1/1:0,26:26:78:1050,78,0\n",
      "chr1\t927744\t.\tG\tT\t649.77\t.\tAC=2;AF=1.00;AN=2;DP=18;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=30.62;SOR=0.804\tGT:AD:DP:GQ:PL\t1/1:0,17:17:51:678,51,0\n",
      "chr1\t928131\t.\tT\tC\t25.78\t.\tAC=1;AF=0.500;AN=2;BaseQRankSum=0.253;ClippingRankSum=0.000;DP=10;ExcessHet=3.0103;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=55.35;MQRankSum=0.493;QD=2.58;ReadPosRankSum=0.253;SOR=1.609\tGT:AD:DP:GQ:PL\t0/1:8,2:10:54:54,0,322\n",
      "chr1\t928141\t.\tC\tG\t227.77\t.\tAC=1;AF=0.500;AN=2;BaseQRankSum=-0.282;ClippingRankSum=0.000;DP=9;ExcessHet=3.0103;FS=3.010;MLEAC=1;MLEAF=0.500;MQ=54.80;MQRankSum=-0.549;QD=25.31;ReadPosRankSum=2.200;SOR=0.160\tGT:AD:DP:GQ:PL\t0/1:2,7:9:63:256,0,63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "print(subprocess.run(f\"gsutil cat {snp_result} | grep -v '^#' | head -n10\",\n",
    "               shell=True, stdout=subprocess.PIPE, encoding=\"utf-8\").stdout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jobs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
