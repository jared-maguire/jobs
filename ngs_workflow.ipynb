{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sk8s\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_image = False\n",
    "populate_reference = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the docker image for our NGS jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcr.io/jared-genome-analysis/ngs-1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if build_image:\n",
    "    image = sk8s.docker_build(image_name=\"ngs-1\",\n",
    "                              conda=[\"bwa\", \"gatk4\", \"samtools\", \"google-cloud-sdk\", \"bedtools\"],\n",
    "                              channels=[\"conda-forge\", \"bioconda\"],\n",
    "                              pip=[\"numpy\", \"scipy\", \"matplotlib\", \"pandas\"],\n",
    "                              additional_config=\"RUN apt-get install -y gcc python3-dev python3-setuptools && pip3 uninstall crcmod && pip3 install --no-cache-dir -U crcmod\")\n",
    "else:    \n",
    "    image = \"gcr.io/jared-genome-analysis/ngs-1\"\n",
    "    #image = \"ngs-1\"\n",
    "\n",
    "image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a volume to hold the reference genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reference-volume'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a volume to store the reference\n",
    "if populate_reference:\n",
    "    reference_volume = sk8s.create_volume(\"100Gi\", name=\"reference-volume\")\n",
    "else:\n",
    "    reference_volume = \"reference-volume\"\n",
    "\n",
    "# Note the default volumes that jobs should mount\n",
    "default_volumes={reference_volume: f\"/mnt/{reference_volume}\"}\n",
    "#default_volumes[\"gcs-creds\"] = f\"/root/.config/gcloud\"\n",
    "\n",
    "def populate_reference_volume(volume):\n",
    "    import subprocess\n",
    "\n",
    "    def run_silent(cmd):\n",
    "        return subprocess.run(cmd, check=True, shell=True,\n",
    "                              stdout=subprocess.PIPE,\n",
    "                              stderr=subprocess.PIPE)\n",
    "\n",
    "    #result = run_silent(f\"\"\"mkdir -p /mnt/{volume}/hg38/ && gsutil -m rsync -r gs://genomics-public-data/references/hg38/v0/ /mnt/{volume}/hg38/\"\"\")\n",
    "    result = run_silent(f\"\"\"mkdir -p /mnt/{volume}/hg38/\"\"\")\n",
    "    result = run_silent(f\"\"\"gsutil -m rsync -r  gs://jared-genome/ref/GRCh38/ /mnt/{volume}/GRCh38/\"\"\")\n",
    "    return \"OK\"\n",
    "\n",
    "if populate_reference:\n",
    "    sk8s.run(populate_reference_volume, reference_volume,\n",
    "             volumes=default_volumes, image=image, asynchro=False)\n",
    "\n",
    "reference_volume"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a very helpful utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(cmd):\n",
    "    import subprocess\n",
    "\n",
    "    result = subprocess.run(cmd,\n",
    "                            check=False,\n",
    "                            shell=True,\n",
    "                            stdout=subprocess.PIPE,\n",
    "                            stderr=subprocess.STDOUT,\n",
    "                            encoding=\"utf-8\")\n",
    "    if result.returncode == 0:\n",
    "        return result.stdout\n",
    "    else:\n",
    "        print(\"Error Running Command.\")\n",
    "        print(\"Command:\", cmd)\n",
    "        print(\"Log:\")\n",
    "        print(result.stdout)\n",
    "        raise subprocess.CalledProcessError(result.returncode, cmd=cmd, output=result.stdout)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare input data (not really part of the pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fq_chunk(bam, region, output_fq):\n",
    "    import os\n",
    "\n",
    "    token = run(\"gcloud auth application-default print-access-token\").strip()\n",
    "    os.environ[\"GCS_OAUTH_TOKEN\"] = token\n",
    "\n",
    "    run(f\"samtools view -b {bam} {region} > ./in.bam\")\n",
    "    run(f\"samtools index in.bam\")\n",
    "    run(f\"samtools collate in.bam out\")\n",
    "    run(f\"samtools fastq -o out.fq out.bam\")\n",
    "    run(f\"gsutil cp out.fq {output_fq}\")\n",
    "\n",
    "    return output_fq\n",
    "\n",
    "\n",
    "def concatenate(input_files, output_file):\n",
    "    import os\n",
    "    run(\"mkdir ./data/\")\n",
    "    run(f\"gsutil -m cp {' '.join(input_files)} ./data/\")\n",
    "    local_input_files = [\"./data/\" + os.path.basename(f) for f in input_files]\n",
    "    run(f\"cat {' '.join(local_input_files)} > out\")\n",
    "    run(f\"gsutil cp out {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "\n",
    "def generate_fq(bam, region_size, output_file):\n",
    "    import subprocess\n",
    "    cmd = f'bedtools makewindows -g /mnt/{reference_volume}/GRCh38/Homo_sapiens_assembly38.fasta.genome -w {region_size} | grep -vP \"_|HLA\"'\n",
    "\n",
    "    regions = [\"{}:{}-{}\".format(*(r.split(\"\\t\")))\n",
    "               for r in\n",
    "               run(cmd).strip().split(\"\\n\")]\n",
    "\n",
    "    jobs = [sk8s.run(generate_fq_chunk, bam, region, f\"gs://jared-genome/sk8s/pipeline_test_1/fastq/chunk_{idx}.fq\",\n",
    "                     image=image, volumes=default_volumes, asynchro=True)\n",
    "            for idx, region in enumerate(regions[0:3])]\n",
    "\n",
    "    fastqs = list(map(sk8s.wait, jobs))\n",
    "\n",
    "    return sk8s.run(concatenate, fastqs, output_file,\n",
    "                    image=image, volumes=default_volumes,\n",
    "                    asynchro=False)\n",
    "\n",
    "\n",
    "results = sk8s.run(generate_fq, \"gs://jared-genome/jared.bam\", int(10e6), \"gs://jared-genome/jared_interleaved.fq\",\n",
    "                   image=image,\n",
    "                   volumes=default_volumes,\n",
    "                   asynchro=False)\n",
    "results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define pipeline tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_fastq(fastq, n_chunks, output_prefix):\n",
    "    import os\n",
    "\n",
    "    run(f\"gsutil cp {fastq} ./input.fq\")\n",
    "\n",
    "    os.mkdir(\"./output/\")\n",
    "    output_files = [f\"./output/chunk_{i}.fq\" for i in range(n_chunks)]\n",
    "    output_fds = [open(f, \"w\") for f in output_files]\n",
    "    current_output = 0\n",
    "    \n",
    "    with open(\"input.fq\") as fp:\n",
    "        while True:\n",
    "            name = fp.readline()\n",
    "            seq = fp.readline()\n",
    "            strand = fp.readline()\n",
    "            qual = fp.readline()\n",
    "            if name == \"\": break\n",
    "            print(name, seq, strand, qual, sep=\"\\n\", end=\"\", file=output_fds[current_output])\n",
    "            current_output = (current_output + 1) % n_chunks\n",
    "    \n",
    "    [f.close() for f in output_fds]\n",
    "\n",
    "    fastqs = []\n",
    "    for idx, file in enumerate(output_files):\n",
    "        fastqs.append(f\"{output_prefix}{idx}.fq\")\n",
    "        run(f\"gsutil cp {file} {output_prefix}{idx}.fq\")\n",
    "\n",
    "    return fastqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align(fq, output_bam, reference, read_group):\n",
    "    run(f\"gsutil -m cp {fq} ./fq.fq\")\n",
    "    run(f'bwa mem -p -R \"{read_group}\" {reference} fq.fq | samtools sort > out.bam')\n",
    "    run(f\"samtools index out.bam\")\n",
    "    run(f\"gsutil -m cp out.bam {output_bam}\")\n",
    "    run(f\"gsutil -m cp out.bam.bai {output_bam}.bai\")\n",
    "    return output_bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_bams(bams, output_bam):\n",
    "    import os\n",
    "    import dill as pickle\n",
    "\n",
    "    os.mkdir(\"./bams/\")\n",
    "\n",
    "    bams_str = \" \".join(bams)\n",
    "    bais_str = \" \".join([f\"{b}.bai\" for b in bams])\n",
    "    run(f\"gsutil -m cp {bais_str} ./bams/\")\n",
    "    run(f\"gsutil -m cp {bams_str} ./bams/\")\n",
    "\n",
    "    run(f\"samtools merge ./out.bam ./bams/*.bam\")\n",
    "    run(f\"samtools index out.bam\")\n",
    "    run(f\"gsutil cp out.bam {output_bam}\")\n",
    "    run(f\"gsutil cp out.bam.bai {output_bam}.bai\")\n",
    "    return output_bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_snps(reference, bam, roi, output_vcf):\n",
    "    import subprocess\n",
    "\n",
    "    #def run_and_log(cmd):\n",
    "    #    proc = subprocess.run(cmd, check=True, shell=True, encoding=\"utf-8\",\n",
    "    #                          stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    #    return dict(cmd=cmd,\n",
    "    #                returncode=proc.returncode,\n",
    "    #                stdout=proc.stdout,\n",
    "    #                stderr=proc.stderr)\n",
    "\n",
    "    region = \"%s:%d-%d\" % roi\n",
    "\n",
    "    run(f\"gsutil cp {bam} ./in.bam\")\n",
    "    run(f\"gsutil cp {bam}.bai ./in.bam.bai\")\n",
    "    run(f\"gatk HaplotypeCaller -R {reference} -I in.bam -O out.vcf -L {region}\")\n",
    "    run(f\"gsutil cp out.vcf {output_vcf}\")\n",
    "\n",
    "    return output_vcf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference=f\"/mnt/{reference_volume}/GRCh38/Homo_sapiens_assembly38.fasta\"\n",
    "sample_name=\"jared\"\n",
    "read_group=f'@RG\\\\tID:{sample_name}\\\\tSM:{sample_name}\\\\tPL:ILLUMINA'\n",
    "#ROI = (\"chr1\", 14674463, 14697776)\n",
    "#chr1:925,893-935,453\n",
    "ROI = (\"chr1\", 925893, 935453)\n",
    "#fq = \"gs://jared-genome/jared_interleaved.fq\"\n",
    "fq = \"gs://jared-genome/tiny_interleaved.fq\"\n",
    "output_prefix = \"gs://jared-genome/sk8s/pipeline_test_1/\"\n",
    "output_bam = f\"{output_prefix}bams/{sample_name}.bam\"\n",
    "output_vcf = f\"{output_prefix}snps/{sample_name}.vcf\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide the unaligned reads into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastqs = sk8s.run(split_fastq, fq, 3, f\"{output_prefix}fastq_chunks/chunk_\",\n",
    "                  image=image, volumes=default_volumes, asynchro=False)\n",
    "fastqs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align each chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bams = sk8s.map(lambda fq: align(fq, output_prefix + \"bam_chunks/\" + re.sub(\"\\.fq$\", \".bam\", os.path.basename(fq)), reference, read_group), fastqs,\n",
    "                image=image, volumes=default_volumes,\n",
    "                requests={\"memory\": \"8Gi\", \"ephemeral-storage\": \"10Gi\", \"cpu\": \"1\"},\n",
    "                limits={\"memory\": \"8Gi\", \"ephemeral-storage\": \"10Gi\"},\n",
    "                asynchro=False)\n",
    "\n",
    "bams"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the aligned chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam = sk8s.run(merge_bams, bams, output_bam,\n",
    "               image=image, volumes=default_volumes,\n",
    "               requests={\"memory\": \"8Gi\", \"ephemeral-storage\": \"10Gi\", \"cpu\": \"1\"},\n",
    "               limits={\"memory\": \"8Gi\", \"ephemeral-storage\": \"10Gi\"},\n",
    "               asynchro=False)\n",
    "bam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Call SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_result = sk8s.run(call_snps, reference, bam, ROI, output_vcf,\n",
    "                       image=image, asynchro=False, volumes=default_volumes,\n",
    "                       requests={\"memory\": \"8Gi\", \"ephemeral-storage\": \"10Gi\", \"cpu\": \"2\"},\n",
    "                       limits={\"memory\": \"8Gi\", \"ephemeral-storage\": \"10Gi\"})\n",
    "snp_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have a look 🧬👀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "print(subprocess.run(f\"gsutil cat {snp_result} | grep -v '^#' | head -n10\",\n",
    "               shell=True, stdout=subprocess.PIPE, encoding=\"utf-8\").stdout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jobs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
