{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sk8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import time\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk8s.map(lambda a: str(a), [1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'running': 3})\n",
      "{'job-uekyy': 'running', 'job-pbbxt': 'running', 'job-sfcjt': 'running'}\n",
      "{'job-uekyy': 'running', 'job-pbbxt': 'running', 'job-sfcjt': 'running'}\n",
      "{'job-uekyy': 'running', 'job-pbbxt': 'running', 'job-sfcjt': 'running'}\n",
      "{'job-uekyy': 'running', 'job-pbbxt': 'running', 'job-sfcjt': 'running'}\n",
      "{'job-uekyy': 'running', 'job-pbbxt': 'running', 'job-sfcjt': 'running'}\n",
      "{'job-uekyy': 'running', 'job-pbbxt': 'success', 'job-sfcjt': 'running'}\n",
      "job-pbbxt success 0.9314090911448614\n",
      "{'job-uekyy': 'running', 'job-sfcjt': 'success'}\n",
      "job-sfcjt success 2.4295227023123056\n",
      "{'job-uekyy': 'running'}\n",
      "{'job-uekyy': 'success'}\n",
      "{'job-uekyy': 'success'}\n",
      "job-uekyy success 7.985610689624255\n",
      "{}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.985610689624255, 0.9314090911448614, 2.4295227023123056]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wait(jobs, delete=True):\n",
    "\n",
    "    def get_job_status_json(jobs):\n",
    "        stdout = subprocess.run(f\"kubectl get jobs {' '.join(jobs)} -o json --ignore-not-found\", \n",
    "                            check=True, shell=True,\n",
    "                            stdout=subprocess.PIPE, stderr=subprocess.PIPE, encoding=\"utf-8\").stdout\n",
    "        try:\n",
    "            return json.loads(stdout)\n",
    "        except json.JSONDecodeError:\n",
    "            return dict(kind=\"List\", items=[])\n",
    "\n",
    "    def check_job_status_json(data):\n",
    "        assert(data[\"kind\"] == \"Job\")\n",
    "        if (\"failed\" in data[\"status\"]) and (data[\"status\"][\"failed\"] >= data[\"spec\"][\"backoffLimit\"]):\n",
    "            return \"failed\"\n",
    "        if \"succeeded\" not in data[\"status\"]:\n",
    "            return \"running\"\n",
    "        if data[\"status\"][\"succeeded\"] == 1:\n",
    "            return \"success\"\n",
    "\n",
    "    def cleanup_job(job_name, delete=True):\n",
    "        log_text = sk8s.logs(job_name, decode=True)\n",
    "        if delete:\n",
    "            sk8s.util.run_cmd(f\"kubectl delete job {job_name}\")\n",
    "        assert(len(log_text.values()) == 1)\n",
    "        return list(log_text.values())[0]\n",
    "\n",
    "    if jobs.__class__ == str:\n",
    "        jobs = [jobs]\n",
    "\n",
    "    data = get_job_status_json(jobs)\n",
    "\n",
    "    results = {d[\"metadata\"][\"name\"]: check_job_status_json(d) for d in data[\"items\"]}\n",
    "    print(Counter(results.values()))\n",
    "\n",
    "    actual_results = dict()  # nice variable name doofus ðŸ˜œ\n",
    "\n",
    "    while True:\n",
    "        data = get_job_status_json(jobs)\n",
    "        results = {d[\"metadata\"][\"name\"]: check_job_status_json(d) for d in data[\"items\"]}\n",
    "        #print(Counter(results.values()))\n",
    "        print(results)\n",
    "        if \"running\" not in results.values(): break\n",
    "\n",
    "        for j, s in results.items():\n",
    "            if s != \"running\":\n",
    "                val = cleanup_job(j, delete=delete)\n",
    "                actual_results[j] = val\n",
    "                print(j, s, val, flush=True)\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Now clean up whatever's left\n",
    "    data = get_job_status_json(jobs)\n",
    "    results = {d[\"metadata\"][\"name\"]: check_job_status_json(d) for d in data[\"items\"]}\n",
    "    print(results)\n",
    "\n",
    "    for j, s in results.items():\n",
    "        val = cleanup_job(j, delete=delete)\n",
    "        actual_results[j] = val\n",
    "        print(j, s, val, flush=True)\n",
    "\n",
    "    data = get_job_status_json(jobs)\n",
    "    results = {d[\"metadata\"][\"name\"]: check_job_status_json(d) for d in data[\"items\"]}\n",
    "    print(results)\n",
    "\n",
    "    return [actual_results[job] for job in jobs]\n",
    "\n",
    "\n",
    "from time import sleep\n",
    "from numpy.random import rand as rand\n",
    "\n",
    "n_jobs = 3\n",
    "jobs = sk8s.map(lambda i: (sleep(i), i)[1], [rand() * 10 for i in range(n_jobs)], asynchro=True)\n",
    "wait(jobs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jobs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
